# RÃ©sume TE1 - TrÃ¼eb Guillaume
````col
```col-md
flexGrow=1
===
## Type d'apprentissage
**Apprentissage automatique** 
L'apprentissage automatique consiste Ã  donner aux ordinateurs la capacitÃ© d'apprendre Ã  partir de donnÃ©es, sans Ãªtre explicitement programmÃ©s.
### Paradigmes d'apprentissage
**Apprentissage supervisÃ©:**
- Les donnÃ©es d'entraÃ®nement sont des paires de tuples (entrÃ©es, sorties dÃ©sirÃ©es).
- **Exemple classification**: Classification des e-mails comme "spam" ou "non-spam". Le modÃ¨le apprend Ã  associer des caractÃ©ristiques spÃ©cifiques des e-mails (entrÃ©es) Ã  leurs Ã©tiquettes correspondantes (sorties dÃ©sirÃ©es).
- **Exemple rÃ©gression**: PrÃ©diction du prix des maisons en fonction de caractÃ©ristiques telles que la superficie, le nombre de chambres, etc. Le modÃ¨le est entraÃ®nÃ© Ã  estimer une valeur continue (prix) Ã  partir des caractÃ©ristiques d'entrÃ©e.
- **Algorithme K-NN (k plus proches voisins) :**
	- **ParamÃ¨tre clÃ© :** K (nombre de voisins Ã  considÃ©rer).
	- **Requis :** Ensemble de donnÃ©es Ã©tiquetÃ©es, mÃ©trique de similaritÃ©.
	- **Fonctionnement :** Choix de K, mesure de la similaritÃ©, sÃ©lection des K plus proches voisins, vote majoritaire pour la classification.
	- ![](../../../../S0/PiecesJointes/Pasted%20image%2020231123114344.png)
- **PreÌdiction**
- **DeÌtection dâ€™anomalies**
- **Authentification**

**Apprentissage semi-supervisÃ©:**
- Les donnÃ©es d'entraÃ®nement contiennent seulement une partie des sorties dÃ©sirÃ©es.

**Apprentissage non supervisÃ©:**
- Les donnÃ©es d'entraÃ®nement ne comportent que des donnÃ©es en entrÃ©e.
- _Exemple:_ Groupement (trouver des groupes de donnÃ©es sans a priori des classes), RÃ©duction de la dimensionnalitÃ©, Prototypage, Compression.

**Reinforcement learning:**
- Les donnÃ©es d'entraÃ®nement fournissent un score suite Ã  une sÃ©quence d'actions.
- _Exemple:_ ProblÃ¨me de contrÃ´le (trouver les actions ou sÃ©quences d'actions pour complÃ©ter une tÃ¢che).

**Apprentissage par renforcement**
 - ProbleÌ€me de controÌ‚le
 - Trouver les actions (ou seÌquences dâ€™actions) pour compleÌter une taÌ‚che

**Deep learning**
- Techniques permettant de donner en entreÌe des donneÌes brutes simplifiant le travail humain dâ€™extraction de caracteÌristiques.

### Diagramme de VoronoiÌˆ
La reÌgion de VoronoiÌˆ est celle qui est composeÌe de tous les points qui sont plus proches dâ€™une observation que dâ€™aucune autre. La classe preÌdite par I-NN pour tous les points dâ€™une reÌgion de VoronoiÌˆ sera donc la meÌ‚me.
![](../../../../S0/PiecesJointes/Pasted%20image%2020231123120115.png)
```
```col-md
flexGrow=1
===
## Analyse exploratoire des donnÃ©es
### Distribution
- **Mode :** La valeur la plus frÃ©quente (unimodale, bimodale ou multimodale).
- **Moyenne :** CalculÃ©e en prenant la somme des valeurs et en la divisant par le nombre de valeurs.
- **MÃ©diane :** La valeur du milieu lorsque les donnÃ©es sont classÃ©es dans l'ordre croissant, prenant la moyenne des deux en cas de nombre pair.
- **Ã‰cart type :** Mesure de la dispersion des valeurs, reprÃ©sentant la moyenne quadratique des Ã©carts par rapport Ã  la moyenne.
### Boite Ã  moustache
![](../../../../S0/PiecesJointes/Pasted%20image%2020231123115728.png)
## Mesures dâ€™Ã©valuation
- **Accuracy :**
  - *Description :* Pourcentage de prÃ©dictions correctes parmi l'ensemble des prÃ©dictions.
  - *Formule :* $$ \frac{{\text{true positives + true negatives}}}{{\text{total de prÃ©dictions rÃ©alisÃ©es}}} \times 100 $$
- **Precision :**
  - *Description :* Proportion de vrais positifs parmi l'ensemble des prÃ©dictions positives.
  - *Formule :* $$ \frac{{\text{true positives}}}{{\text{true positives + false positives}}} $$
- **Recall :**
  - *Description :* Proportion de vrais positifs parmi l'ensemble rÃ©el des positifs.
  - *Formule :* $$ \frac{{\text{true positives}}}{{\text{true positives + false negatives}}} $$
- **F-score :**
  - *Description :* Une mÃ©trique unique combinant precision et recall.
  - *Formule :* $$ \frac{{2 \cdot \text{precision} \cdot \text{recall}}}{{\text{precision + recall}}} $$
- **Specificity :**
  - *Description :* Proportion de vrais nÃ©gatifs parmi l'ensemble rÃ©el des nÃ©gatifs.
  - *Formule :* $$ \frac{{\text{true negatives}}}{{\text{true negatives + false positives}}} $$
```
````

````col
```col-md
flexGrow=1
===
#### Quel K utiliser?
**Avantages dâ€™un grand K:**
- Meilleure confiance, surtout si les donneÌes sont bruiteÌes
- Fournit une reÌponse â€œprobabilisteâ€
	- Le ratio dâ€™exemples utiliseÌ pour chaque preÌdiction donne une information sur la confiance ou lâ€™ambiguiÌˆteÌ de la deÌcision
- Le consensus quâ€™il construit aÌ€ partir des k voisins conduit aÌ€ une seÌparation de lâ€™espace dâ€™entreÌe plus simple; aussi appeleÌe limite de deÌcision

**DeÌsavantages dâ€™un grand K:**
- DeÌtruit la localiteÌ de lâ€™estimation puisque des exemples plus eÌloigneÌs sont pris en compte
- Augmente la charge de calcul

**Avantages dâ€™un petit K:**
- Exploite au mieux lâ€™information locale en donnant plus dâ€™importance aÌ€ chaque point de la base de donneÌes dâ€™exemples:  e.g. pour k=1
- Il nâ€™est pas treÌ€s robuste face au bruit dans les donneÌes

**Classification ambiguÌˆe**
- Avec un K pair il est possible dâ€™avoir des reÌgions qui nâ€™ont pas de classe majoritaire et sont donc ambigue.
```
```col-md
flexGrow=1
===
### Evaluation des modeÌ€les
On attend dâ€™un modeÌ€le creÌeÌ par apprentissage automatique de pouvoir geÌneÌraliser au-delaÌ€ des donneÌes dâ€™entraiÌ‚nement.
- **Overfitting**: le modeÌ€le repreÌsente â€œtrop bienâ€ les donneÌes dâ€™exemple
	- Mauvasie performance face aÌ€ de nouvelles donneÌes
	- ModeÌ€le excessivement complexe, apprentissage â€œpar coeurâ€ des exemples
- **Underfitting**: le modeÌ€le ne repreÌsente pas suffisamment bien les donneÌes dâ€™exemple
	- ModeÌ€le excessivement simple

> [!important]
> Lâ€™overfitting et lâ€™underfitting sont les causes prinicipales de mauvaises performances (mauvaise geÌneÌralisation).

![](../../../../S0/PiecesJointes/Pasted%20image%2020231123120536.png)

**Validation hold-out**
- ReÌserver une partie des donneÌes disponibles pour tester la performance du modeÌ€le.
- Pour ne pas mal estimer la capaciteÌ de geÌneÌralisation, eÌvaluer plusieurs fois la performance du modeÌ€le en divisant aleÌatoirement et diffeÌremment la base de donneÌes en train-test.
- Calculer une performance moyenne aÌ€ partir de ses multiples tests.


**Validation croisÃ©e**
- Diviser la base de donneÌes en ğ‘› â€œfoldsâ€, entrainer le modeÌ€le avec $\frac{ğ‘›âˆ’1}{n}$ des
donneÌes et tester avec les ğ‘› des donneÌes restant. ReÌpeÌter ceci ğ‘› fois et calculer la moyenne ou le pire de cas.


**Evaluation compleÌ€te**
- Utiliser la meÌthode de validation croiseÌe pour seÌlectionner le modeÌ€le final. ReÌserver une partie de la base de donneÌes pour eÌvaluer le modeÌ€le final (test set).

```
````
